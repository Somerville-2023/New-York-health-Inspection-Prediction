{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4180b3-a138-4e09-8d24-786ece8cff31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wrangle import wrangle_zillow, train_val_test, xy_split\n",
    "from evaluate import plot_residuals, regression_errors, baseline_mean_errors, better_than_baseline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor, plot_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------ SCALE DATA FUNCTION --------------------\n",
    "def scale_data(train, val, test, to_scale):\n",
    "    # make copies for scaling\n",
    "    train_scaled = train.copy()\n",
    "    validate_scaled = val.copy()\n",
    "    test_scaled = test.copy()\n",
    "\n",
    "    #make the thing\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    #fit the thing\n",
    "    scaler.fit(train[to_scale])\n",
    "\n",
    "    #use the thing\n",
    "    train_scaled[to_scale] = scaler.transform(train[to_scale])\n",
    "    validate_scaled[to_scale] = scaler.transform(val[to_scale])\n",
    "    test_scaled[to_scale] = scaler.transform(test[to_scale])\n",
    "    \n",
    "    return train_scaled, validate_scaled, test_scaled\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def eval_model(y_actual, y_hat):\n",
    "    \n",
    "    return sqrt(mean_squared_error(y_actual, y_hat))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_val, y_val):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_preds = model.predict(X_train)\n",
    "    \n",
    "    train_rmse = eval_model(y_train, train_preds)\n",
    "    \n",
    "    val_preds = model.predict(X_val)\n",
    "    \n",
    "    val_rmse = eval_model(y_val, val_preds)\n",
    "    \n",
    "    print(f'The train RMSE is {train_rmse:.2f}.\\n')\n",
    "    print(f'The validate RMSE is {val_rmse:.2f}.\\n\\n')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------ Train and eval function -------------------------------------\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train a machine learning model and evaluate its performance on training and validation data.\n",
    "    \n",
    "    Args:\n",
    "        model (object): The machine learning model to be trained.\n",
    "        X_train (array-like): Training feature data.\n",
    "        y_train (array-like): Training target data.\n",
    "        X_val (array-like): Validation feature data.\n",
    "        y_val (array-like): Validation target data.\n",
    "        \n",
    "    Returns:\n",
    "        object: The trained model.\n",
    "        float: The training RMSE.\n",
    "        float: The validation RMSE.\n",
    "    \"\"\"\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on training and validation data\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_val)\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    train_rmse = eval_model(y_train, train_preds)\n",
    "    val_rmse = eval_model(y_val, val_preds)\n",
    "\n",
    "    # Calculate R-squared (R2) for training and validation sets\n",
    "    train_r2 = r2_score(y_train, train_preds)\n",
    "    val_r2 = r2_score(y_val, val_preds)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f'The train RMSE is {train_rmse:.2f}.\\n')\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f'The validation RMSE is {val_rmse:.2f}.\\n\\n')\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nTraining R-squared (R2): {train_r2:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nValidation R-squared (R2): {val_r2:.2f}\")\n",
    "    \n",
    "    return model, train_rmse, val_rmse\n",
    "\n",
    "# Example usage:\n",
    "# trained_model, train_rmse, val_rmse = train_and_evaluate_model(model, X_train, y_train, X_val, y_val)\n",
    "\n",
    "\n",
    "# --------------------------------- Zillow plot and model train -----------------------\\\n",
    "\n",
    "def wrangle_zillow_and_train_model():\n",
    "    # Wrangle the data\n",
    "    df = wrangle_zillow()\n",
    "\n",
    "    # Drop categorical features\n",
    "    df = df.drop(columns=['property_county_landuse_code', 'property_zoning_desc', 'n-prop_type', 'n-av_room_size', 'state'])\n",
    "\n",
    "    # Train-test split\n",
    "    train, val, test = train_val_test(df)\n",
    "\n",
    "    # Split data into X and y for train and val\n",
    "    X_train, y_train = xy_split(train, 'home_value')\n",
    "    X_val, y_val = xy_split(val, 'home_value')\n",
    "\n",
    "    # Calculate baseline\n",
    "    bl = y_train.median()\n",
    "\n",
    "    # Create a DataFrame to work with\n",
    "    preds = pd.DataFrame({'y_actual' : y_train,\n",
    "                          'y_baseline': bl})\n",
    "\n",
    "    # Calculate baseline residuals\n",
    "    preds['y_baseline_residuals'] = bl - preds['y_actual']\n",
    "\n",
    "    # Initialize and fit a linear regression model\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions with the model\n",
    "    preds['y_hat'] = lm.predict(X_train)\n",
    "\n",
    "    # Calculate model residuals\n",
    "    preds['y_hat_residuals'] = preds['y_hat'] - preds['y_actual']\n",
    "\n",
    "    # Plot residuals\n",
    "    plot_residuals(preds.y_actual, preds.y_hat)\n",
    "\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    # Calculate regression errors\n",
    "    SSE, ESS, TSS, MSE, RMSE = regression_errors(preds.y_actual, preds.y_hat)\n",
    "    print(f\"\\nModel RMSE: {RMSE:.2f}\\n\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "\n",
    "    # Calculate baseline errors\n",
    "    SSE_baseline, MSE_baseline, RMSE_baseline = baseline_mean_errors(preds.y_actual)\n",
    "    print(f\"\\nBaseline RMSE: {RMSE_baseline:.2f}\\n\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================ model function =============================\n",
    "def model_xy():\n",
    "# Wrangle the data\n",
    "    df = wrangle_zillow()\n",
    "\n",
    "    # Drop categorical features\n",
    "    df = df.drop(columns=['property_county_landuse_code', 'property_zoning_desc', 'n-prop_type', 'n-av_room_size', 'state'])\n",
    "\n",
    "    # Train-test split\n",
    "    train, val, test = train_val_test(df)\n",
    "\n",
    "    # Split data into X and y for train and val\n",
    "    X_train, y_train = xy_split(train, 'home_value')\n",
    "    X_val, y_val = xy_split(val, 'home_value')\n",
    "    X_test, y_test = xy_split(test, 'home_value')\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "def model_1(X_train, y_train, X_val, y_val):\n",
    "    # Initialize the RandomForestRegressor\n",
    "    rfr = RandomForestRegressor()\n",
    "    \n",
    "    # Train the model on the training data\n",
    "    rfr.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on training and validation sets\n",
    "    train_preds = rfr.predict(X_train)\n",
    "    val_preds = rfr.predict(X_val)\n",
    "    \n",
    "    # Calculate RMSE for training and validation sets\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, train_preds))\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "    \n",
    "    # Calculate R-squared (R2) for training and validation sets\n",
    "    train_r2 = r2_score(y_train, train_preds)\n",
    "    val_r2 = r2_score(y_val, val_preds)\n",
    "    \n",
    "    # Print the metrics\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nTraining RMSE: {train_rmse:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nValidation RMSE: {val_rmse:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nTraining R-squared (R2): {train_r2:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nValidation R-squared (R2): {val_r2:.2f}\")\n",
    "    \n",
    "    return rfr\n",
    "\n",
    "# Example usage:\n",
    "# rfr = RandomForestRegressor()\n",
    "# trained_model = train_and_evaluate_model(rfr, X_train, y_train, X_val, y_val)\n",
    "\n",
    "# ======================================= model 2 ============================================\\\n",
    "\n",
    "\n",
    "def model_2(df, target_column, X_val, y_val, early_stopping_rounds=10, params=None):\n",
    "\n",
    "    # acquire data\n",
    "    df = wrangle_zillow()\n",
    "\n",
    "    # Drop categorical features\n",
    "    df = df.drop(columns=['property_county_landuse_code', 'property_zoning_desc', 'n-prop_type', 'n-av_room_size', 'state'])\n",
    "    \n",
    "    # Train-test split\n",
    "    train, val, test = train_val_test(df)\n",
    "\n",
    "    # Split data into X and y\n",
    "    X_train, y_train = xy_split(df, target_column)\n",
    "    \n",
    "    # Define the hyperparameters for your XGBoost model (or pass them as an argument)\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 300,\n",
    "            'max_depth': 4,\n",
    "            'early_stopping_rounds': early_stopping_rounds,\n",
    "            # Add other hyperparameters as needed\n",
    "        }\n",
    "\n",
    "    # Define weight data (you can replace this with your actual weights)\n",
    "    sample_weights = np.ones(X_train.shape[0])  # Example: All weights are set to 1\n",
    "    \n",
    "    # Create the XGBoost regressor with your specified hyperparameters\n",
    "    xgb = XGBRegressor(**params)\n",
    "    \n",
    "    # Fit the model to your training data with eval_set and verbose\n",
    "    xgb.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False, sample_weight=sample_weights)\n",
    "\n",
    "    # Access the best iteration and best score\n",
    "    best_iteration = xgb.best_iteration\n",
    "    best_score = xgb.best_score\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    val_preds = xgb.predict(X_val)\n",
    "    \n",
    "    # Calculate RMSE and R2 for the validation set\n",
    "    val_rmse = np.sqrt(mean_squared_error(y_val, val_preds))\n",
    "    val_r2 = r2_score(y_val, val_preds)\n",
    "    \n",
    "    # Create a dictionary to store the results\n",
    "    results = {\n",
    "        'model': xgb,\n",
    "        'val_rmse': val_rmse,\n",
    "        'val_r2': val_r2,\n",
    "        'best_iteration': best_iteration,\n",
    "        'best_score': best_score\n",
    "    }\n",
    "    \n",
    "    # Print the metrics within the function\n",
    "    print(f\"\\n\\n\\n-------------------------------------\")\n",
    "    print(f\"\\nValidation RMSE: {val_rmse:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nValidation R-squared (R2): {val_r2:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nBest Iteration: {best_iteration}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nBest Score: {best_score}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# ========================================= model 3 ================================================\n",
    "\n",
    "def model_3():\n",
    "\n",
    "        # acquire data\n",
    "        df = wrangle_zillow()\n",
    "    \n",
    "        # Drop categorical features\n",
    "        df = df.drop(columns=['parcel_id',\n",
    "                              'property_county_landuse_code', \n",
    "                              'property_zoning_desc', \n",
    "                              'n-prop_type', \n",
    "                              'n-av_room_size', \n",
    "                              'state',\n",
    "                              'region_id_county',\n",
    "                              'region_id_zip',\n",
    "                              'latitude',\n",
    "                              'longitude',\n",
    "                              'lot_area',\n",
    "                              'bedrooms',\n",
    "                              'basement_sqft',\n",
    "                              'fips',\n",
    "                              'rooms',\n",
    "                              'num_stories',\n",
    "                              'year_built',\n",
    "                              'property_landuse_type_id',\n",
    "                              'ac_type_id',\n",
    "                              'building_quality_type_id',\n",
    "                              'heating_or_system_type_id',\n",
    "                              'deck_type_id',\n",
    "                              'unit_cnt',\n",
    "                              'garage_car_cnt',\n",
    "                              'garage_total_sqft',\n",
    "                              'pool_cnt',\n",
    "                              'pool_size_sum',\n",
    "                              'pool_type_id_2',\n",
    "                              'pool_type_id_7',\n",
    "                              'fire_place_cnt',\n",
    "                              'fire_place_flag',\n",
    "                              'has_hot_tub_or_spa',\n",
    "                              'patio_sqft',\n",
    "                              'storage_sqft',\n",
    "                              'tax_delinquency_flag',\n",
    "                              'raw_census_tract_and_block',\n",
    "                              'n-life',\n",
    "                              'n-living_area_error',\n",
    "                              'n-living_area_prop',\n",
    "                              'n-living_area_prop2',\n",
    "                              'n-extra_space',\n",
    "                              'n-extra_space-2',\n",
    "                              'n-gar_pool_ac',\n",
    "                              'n-location',\n",
    "                              'n-location-2',\n",
    "                              'n-location-2round',\n",
    "                              'n-latitude-round',\n",
    "                              'n-longitude-round',\n",
    "                              'n-zip_count',\n",
    "                              'n-county_count',                                    \n",
    "                              'n-ac_ind',\n",
    "                              'n-heat_ind',\n",
    "                              'Small',\n",
    "                              'Medium',\n",
    "                              'Large'])\n",
    "        \n",
    "        # Train-test split\n",
    "        train, val, test = train_val_test(df)\n",
    "        \n",
    "        # Split subsets into X and y only for train and val, not doing test just yet\n",
    "        X_train, y_train = xy_split(train, 'home_value')\n",
    "        X_val, y_val = xy_split(val, 'home_value')\n",
    "        \n",
    "        # Calculate mean and median of y_train\n",
    "        y_train_mean = y_train.mean()\n",
    "        y_train_median = y_train.median()\n",
    "        \n",
    "        # Create a DataFrame with y_train statistics\n",
    "        bl = pd.DataFrame({\"y_actual\" : y_train,\n",
    "                           \"y_mean\" : y_train_mean,\n",
    "                           \"y_median\" : y_train_median})\n",
    "        \n",
    "        # Apply polynomial feature transformation\n",
    "        poly = PolynomialFeatures()\n",
    "        X_train = poly.fit_transform(X_train)\n",
    "        X_val = poly.transform(X_val)\n",
    "\n",
    "        \n",
    "    \n",
    "        # Train a Linear Regression model and evaluate it\n",
    "        lm = LinearRegression()\n",
    "        trained_model, train_rmse, val_rmse = train_and_evaluate_model(lm, X_train, y_train, X_val, y_val)\n",
    "        \n",
    "        # Return the trained model and evaluation metrics\n",
    "        return {\n",
    "            'model': trained_model,\n",
    "            'train_rmse': train_rmse,\n",
    "            'val_rmse': val_rmse,\n",
    "            'y_train_mean': y_train_mean,\n",
    "            'y_train_median': y_train_median,\n",
    "            'y_train_stats': bl\n",
    "        }\n",
    "\n",
    "# ======================== final model and visualization ===============================\n",
    "def final_model(df, target_column, X_test, y_test, early_stopping_rounds=10, params=None):\n",
    "    \n",
    "    # acquire data\n",
    "    df = wrangle_zillow()\n",
    "\n",
    "    # Drop categorical features\n",
    "    df = df.drop(columns=['property_county_landuse_code', 'property_zoning_desc', 'n-prop_type', 'n-av_room_size', 'state'])\n",
    "    \n",
    "    # Train-test split\n",
    "    train, val, test = train_val_test(df)\n",
    "\n",
    "    # Split data into X and y\n",
    "    X_train, y_train = xy_split(df, target_column)\n",
    "    X_test, y_test = xy_split(df, target_column)\n",
    "    \n",
    "    # Define the hyperparameters for your XGBoost model (or pass them as an argument)\n",
    "    if params is None:\n",
    "        params = {\n",
    "            'learning_rate': 0.1,\n",
    "            'n_estimators': 300,\n",
    "            'max_depth': 4,\n",
    "            'early_stopping_rounds': early_stopping_rounds,\n",
    "            # Add other hyperparameters as needed\n",
    "        }\n",
    "\n",
    "\n",
    "    # Define weight data (you can replace this with your actual weights)\n",
    "    sample_weights = np.ones(X_train.shape[0])  # Example: All weights are set to 1\n",
    "    \n",
    "    # Create the XGBoost regressor with your specified hyperparameters\n",
    "    xgb = XGBRegressor(**params)\n",
    "    \n",
    "    # Fit the model to your training data with eval_set and verbose\n",
    "    xgb.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False, sample_weight=sample_weights)\n",
    "\n",
    "    # Access the best iteration and best score\n",
    "    best_iteration = xgb.best_iteration\n",
    "    best_score = xgb.best_score\n",
    "    \n",
    "    # Make predictions on validation set\n",
    "    test_preds = xgb.predict(X_test)\n",
    "\n",
    "    # Create a scatter plot of actual vs. predicted values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x=y_test, y=test_preds, alpha=0.5, color='orange')\n",
    "    plt.title(\"Actual vs. Predicted Values\")\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate RMSE and R2 for the validation set\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, test_preds))\n",
    "    test_r2 = r2_score(y_test, test_preds)\n",
    "    \n",
    "    # Create a dictionary to store the results\n",
    "    results = {\n",
    "        'model': xgb,\n",
    "        'val_rmse': test_rmse,\n",
    "        'val_r2': test_r2,\n",
    "        'best_iteration': best_iteration,\n",
    "        'best_score': best_score\n",
    "    }\n",
    "    \n",
    "    # Print the metrics within the function\n",
    "    print(f\"\\n\\n\\n-------------------------------------\")\n",
    "    print(f\"\\nTest RMSE: {test_rmse:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nTest R-squared (R2): {test_r2:.2f}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nBest Iteration: {best_iteration}\")\n",
    "    print(f\"\\n-------------------------------------\")\n",
    "    print(f\"\\nBest Score: {best_score}\")\n",
    "    \n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
