{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import env\n",
    "import john_acquire as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set the option to display all columns\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "app_token = env.app_token\n",
    "year_to_retrieve = '2023'\n",
    "max_req = 100  # Specify the maximum number of observations to retrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file for 2023 already exists. Loading data from the CSV.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>dba</th>\n",
       "      <th>boro</th>\n",
       "      <th>building</th>\n",
       "      <th>street</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>phone</th>\n",
       "      <th>cuisine_description</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>action</th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_description</th>\n",
       "      <th>critical_flag</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade_date</th>\n",
       "      <th>record_date</th>\n",
       "      <th>inspection_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>community_board</th>\n",
       "      <th>council_district</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>nta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50124301</td>\n",
       "      <td>YUMMY JUICE BAR</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>737A</td>\n",
       "      <td>LYDIG AVENUE</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>3472936151</td>\n",
       "      <td>Juice, Smoothies, Fruit Salads</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>10B</td>\n",
       "      <td>Anti-siphonage or back-flow prevention device ...</td>\n",
       "      <td>Not Critical</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Pre-permit (Operational) / Re-inspection</td>\n",
       "      <td>40.854471</td>\n",
       "      <td>-73.866174</td>\n",
       "      <td>211.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>22403.0</td>\n",
       "      <td>2049410.0</td>\n",
       "      <td>2.043190e+09</td>\n",
       "      <td>BX49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50106430</td>\n",
       "      <td>PAN TODO RICO</td>\n",
       "      <td>Queens</td>\n",
       "      <td>7617</td>\n",
       "      <td>ROOSEVELT AVE</td>\n",
       "      <td>11372.0</td>\n",
       "      <td>6466393116</td>\n",
       "      <td>Bakery Products/Desserts</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04H</td>\n",
       "      <td>Raw, cooked or prepared food is adulterated, c...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>32.0</td>\n",
       "      <td>C</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "      <td>40.747064</td>\n",
       "      <td>-73.889337</td>\n",
       "      <td>403.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>4029880.0</td>\n",
       "      <td>4.012870e+09</td>\n",
       "      <td>QN28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50129821</td>\n",
       "      <td>MEI JUNG MEI CHINESE RESTAURANT</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>1402</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>11210.0</td>\n",
       "      <td>9292509943</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04L</td>\n",
       "      <td>Evidence of mice or live mice in establishment...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>18.0</td>\n",
       "      <td>B</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Pre-permit (Operational) / Re-inspection</td>\n",
       "      <td>40.636380</td>\n",
       "      <td>-73.951435</td>\n",
       "      <td>314.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>3120854.0</td>\n",
       "      <td>3.052260e+09</td>\n",
       "      <td>BK42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50057824</td>\n",
       "      <td>SERAFINA LUDLOW</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>98</td>\n",
       "      <td>RIVINGTON STREET</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>2123589800</td>\n",
       "      <td>Italian</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>08A</td>\n",
       "      <td>Establishment is not free of harborage or cond...</td>\n",
       "      <td>Not Critical</td>\n",
       "      <td>19.0</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "      <td>40.720111</td>\n",
       "      <td>-73.988463</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>1084639.0</td>\n",
       "      <td>1.004110e+09</td>\n",
       "      <td>MN27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41399360</td>\n",
       "      <td>NEW RONG HANG RESTAURANT</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>38</td>\n",
       "      <td>ELDRIDGE STREET</td>\n",
       "      <td>10002.0</td>\n",
       "      <td>2126258999</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04M</td>\n",
       "      <td>Live roaches in facility's food or non-food area.</td>\n",
       "      <td>Critical</td>\n",
       "      <td>27.0</td>\n",
       "      <td>B</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "      <td>40.715711</td>\n",
       "      <td>-73.993204</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>1003876.0</td>\n",
       "      <td>1.003000e+09</td>\n",
       "      <td>MN27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      camis                              dba       boro building  \\\n",
       "0  50124301                  YUMMY JUICE BAR      Bronx     737A   \n",
       "1  50106430                    PAN TODO RICO     Queens     7617   \n",
       "2  50129821  MEI JUNG MEI CHINESE RESTAURANT   Brooklyn     1402   \n",
       "3  50057824                  SERAFINA LUDLOW  Manhattan       98   \n",
       "4  41399360         NEW RONG HANG RESTAURANT  Manhattan       38   \n",
       "\n",
       "             street  zipcode       phone             cuisine_description  \\\n",
       "0      LYDIG AVENUE  10462.0  3472936151  Juice, Smoothies, Fruit Salads   \n",
       "1     ROOSEVELT AVE  11372.0  6466393116        Bakery Products/Desserts   \n",
       "2   FLATBUSH AVENUE  11210.0  9292509943                         Chinese   \n",
       "3  RIVINGTON STREET  10002.0  2123589800                         Italian   \n",
       "4   ELDRIDGE STREET  10002.0  2126258999                         Chinese   \n",
       "\n",
       "           inspection_date                                           action  \\\n",
       "0  2023-01-03T00:00:00.000  Violations were cited in the following area(s).   \n",
       "1  2023-01-03T00:00:00.000  Violations were cited in the following area(s).   \n",
       "2  2023-01-03T00:00:00.000  Violations were cited in the following area(s).   \n",
       "3  2023-01-03T00:00:00.000  Violations were cited in the following area(s).   \n",
       "4  2023-01-03T00:00:00.000  Violations were cited in the following area(s).   \n",
       "\n",
       "  violation_code                              violation_description  \\\n",
       "0            10B  Anti-siphonage or back-flow prevention device ...   \n",
       "1            04H  Raw, cooked or prepared food is adulterated, c...   \n",
       "2            04L  Evidence of mice or live mice in establishment...   \n",
       "3            08A  Establishment is not free of harborage or cond...   \n",
       "4            04M  Live roaches in facility's food or non-food area.   \n",
       "\n",
       "  critical_flag  score grade               grade_date  \\\n",
       "0  Not Critical   12.0     A  2023-01-03T00:00:00.000   \n",
       "1      Critical   32.0     C  2023-01-03T00:00:00.000   \n",
       "2      Critical   18.0     B  2023-01-03T00:00:00.000   \n",
       "3  Not Critical   19.0     N                      NaN   \n",
       "4      Critical   27.0     B  2023-01-03T00:00:00.000   \n",
       "\n",
       "               record_date                           inspection_type  \\\n",
       "0  2023-10-24T06:00:07.000  Pre-permit (Operational) / Re-inspection   \n",
       "1  2023-10-24T06:00:07.000          Cycle Inspection / Re-inspection   \n",
       "2  2023-10-24T06:00:07.000  Pre-permit (Operational) / Re-inspection   \n",
       "3  2023-10-24T06:00:07.000     Cycle Inspection / Initial Inspection   \n",
       "4  2023-10-24T06:00:07.000          Cycle Inspection / Re-inspection   \n",
       "\n",
       "    latitude  longitude  community_board  council_district  census_tract  \\\n",
       "0  40.854471 -73.866174            211.0              13.0       22403.0   \n",
       "1  40.747064 -73.889337            403.0              25.0       28700.0   \n",
       "2  40.636380 -73.951435            314.0              45.0       77000.0   \n",
       "3  40.720111 -73.988463            103.0               1.0        3001.0   \n",
       "4  40.715711 -73.993204            103.0               1.0        1600.0   \n",
       "\n",
       "         bin           bbl   nta  \n",
       "0  2049410.0  2.043190e+09  BX49  \n",
       "1  4029880.0  4.012870e+09  QN28  \n",
       "2  3120854.0  3.052260e+09  BK42  \n",
       "3  1084639.0  1.004110e+09  MN27  \n",
       "4  1003876.0  1.003000e+09  MN27  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspections_df = a.get_health_inspection_data(year_to_retrieve, app_token)\n",
    "inspections_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspections_df.head(5).to_csv('inspections_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 73512 entries, 0 to 73511\n",
      "Data columns (total 26 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   camis                  73512 non-null  int64  \n",
      " 1   dba                    73508 non-null  object \n",
      " 2   boro                   73512 non-null  object \n",
      " 3   building               73454 non-null  object \n",
      " 4   street                 73512 non-null  object \n",
      " 5   zipcode                72777 non-null  float64\n",
      " 6   phone                  73512 non-null  object \n",
      " 7   cuisine_description    73512 non-null  object \n",
      " 8   inspection_date        73512 non-null  object \n",
      " 9   action                 73512 non-null  object \n",
      " 10  violation_code         73127 non-null  object \n",
      " 11  violation_description  73127 non-null  object \n",
      " 12  critical_flag          73512 non-null  object \n",
      " 13  score                  70147 non-null  float64\n",
      " 14  grade                  41234 non-null  object \n",
      " 15  grade_date             34354 non-null  object \n",
      " 16  record_date            73512 non-null  object \n",
      " 17  inspection_type        73512 non-null  object \n",
      " 18  latitude               73425 non-null  float64\n",
      " 19  longitude              73425 non-null  float64\n",
      " 20  community_board        72627 non-null  float64\n",
      " 21  council_district       72625 non-null  float64\n",
      " 22  census_tract           72625 non-null  float64\n",
      " 23  bin                    72251 non-null  float64\n",
      " 24  bbl                    73362 non-null  float64\n",
      " 25  nta                    72627 non-null  object \n",
      "dtypes: float64(9), int64(1), object(16)\n",
      "memory usage: 14.6+ MB\n"
     ]
    }
   ],
   "source": [
    "inspections_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_places_api_key = env.g_places_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Select the 5th row (index 4) for testing\n",
    "row = inspections_df.iloc[4]\n",
    "\n",
    "# Construct the text query using dba, street, and zipcode\n",
    "text_query = f\"{row['dba']} {row['street']}\"\n",
    "if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "    text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "\n",
    "# Define the query\n",
    "data = {\n",
    "    'textQuery': text_query\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the POST request\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "# Process the response\n",
    "if response.status_code == 200:\n",
    "    data = response.json().get('places', [])\n",
    "    print(\"Received data:\", data)\n",
    "else:\n",
    "    print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ChIJGXeLPyhawokRXK9zCnvTMuQ',\n",
       "  'formattedAddress': '38 Eldridge St, New York, NY 10002, USA',\n",
       "  'displayName': {'text': 'Rong Hang', 'languageCode': 'en'},\n",
       "  'reviews': [{'name': 'places/ChIJGXeLPyhawokRXK9zCnvTMuQ/reviews/ChdDSUhNMG9nS0VJQ0FnSUNoMllXb2h3RRAB',\n",
       "    'relativePublishTimeDescription': '8 months ago',\n",
       "    'rating': 4,\n",
       "    'text': {'text': \"It's an authentic Fu Zhou restaurant but can be a little daunting for people not from this area. Servers spoke Fu Zhou accents and menu items mostly are at market price. However the seafood is very fresh and tasty. You really have to bring a friend who knows their language so that they can order off menu items!\\n\\nThey allow smoking in the restaurant which I don't really like. It can get very noisy too sometimes.\",\n",
       "     'languageCode': 'en'},\n",
       "    'originalText': {'text': \"It's an authentic Fu Zhou restaurant but can be a little daunting for people not from this area. Servers spoke Fu Zhou accents and menu items mostly are at market price. However the seafood is very fresh and tasty. You really have to bring a friend who knows their language so that they can order off menu items!\\n\\nThey allow smoking in the restaurant which I don't really like. It can get very noisy too sometimes.\",\n",
       "     'languageCode': 'en'},\n",
       "    'authorAttribution': {'displayName': 'Cindy Yang',\n",
       "     'uri': 'https://www.google.com/maps/contrib/100791926269017563938/reviews',\n",
       "     'photoUri': 'https://lh3.googleusercontent.com/a-/ALV-UjUi29IHVoBkeMsT6egmfPjKKSq_Ah5Kowh4ZoSOMKM6fRlR=s128-c0x00000000-cc-rp-mo-ba6'},\n",
       "    'publishTime': '2023-02-17T01:12:29Z'},\n",
       "   {'name': 'places/ChIJGXeLPyhawokRXK9zCnvTMuQ/reviews/ChZDSUhNMG9nS0VJQ0FnSUN4dHRTSWRnEAE',\n",
       "    'relativePublishTimeDescription': '5 months ago',\n",
       "    'rating': 5,\n",
       "    'text': {'text': 'I’ll try again for more choices that might not show in the main menu, which is more authentic! Service fruits after meal.',\n",
       "     'languageCode': 'en'},\n",
       "    'originalText': {'text': 'I’ll try again for more choices that might not show in the main menu, which is more authentic! Service fruits after meal.',\n",
       "     'languageCode': 'en'},\n",
       "    'authorAttribution': {'displayName': 'Laura',\n",
       "     'uri': 'https://www.google.com/maps/contrib/102619440479154790282/reviews',\n",
       "     'photoUri': 'https://lh3.googleusercontent.com/a-/ALV-UjX2RmhTvOXdzocyXdCrbMTWAqLmwKYqnh_MB5iI3E_QAvc=s128-c0x00000000-cc-rp-mo'},\n",
       "    'publishTime': '2023-05-17T07:06:55Z'},\n",
       "   {'name': 'places/ChIJGXeLPyhawokRXK9zCnvTMuQ/reviews/ChZDSUhNMG9nS0VJQ0FnSURVZzRpcGJBEAE',\n",
       "    'relativePublishTimeDescription': '4 years ago',\n",
       "    'rating': 3,\n",
       "    'text': {'text': 'We did not intend to come here, but they have an A grade and the place we were going to next door had a C grade.  The food is ok.  The prices are questionable since most the menu is \"SP\" which i think is market price.  They give you a peanut/pickled something dish as an appatizer which isnt bad.  The shrimp dish was a little pricey for what it was. But it was fresh.  And they have beer if you want it.  We also got two lobsters for $50 which isnt a great deal, but it did taste good.',\n",
       "     'languageCode': 'en'},\n",
       "    'originalText': {'text': 'We did not intend to come here, but they have an A grade and the place we were going to next door had a C grade.  The food is ok.  The prices are questionable since most the menu is \"SP\" which i think is market price.  They give you a peanut/pickled something dish as an appatizer which isnt bad.  The shrimp dish was a little pricey for what it was. But it was fresh.  And they have beer if you want it.  We also got two lobsters for $50 which isnt a great deal, but it did taste good.',\n",
       "     'languageCode': 'en'},\n",
       "    'authorAttribution': {'displayName': 'William Crawford',\n",
       "     'uri': 'https://www.google.com/maps/contrib/114460569621658583105/reviews',\n",
       "     'photoUri': 'https://lh3.googleusercontent.com/a-/ALV-UjUK8-GhuQqoAE9yr58gdrvMWhKog7swBHrI_2lyfyPrgSVH=s128-c0x00000000-cc-rp-mo-ba5'},\n",
       "    'publishTime': '2019-09-02T02:04:50Z'},\n",
       "   {'name': 'places/ChIJGXeLPyhawokRXK9zCnvTMuQ/reviews/ChZDSUhNMG9nS0VJQ0FnSURXa3JXUGFBEAE',\n",
       "    'relativePublishTimeDescription': 'a year ago',\n",
       "    'rating': 5,\n",
       "    'text': {'text': 'Had quick lunch. Mei fun noodle $5 plus seafood add on for $4. No tip. Food was good and service was quick',\n",
       "     'languageCode': 'en'},\n",
       "    'originalText': {'text': 'Had quick lunch. Mei fun noodle $5 plus seafood add on for $4. No tip. Food was good and service was quick',\n",
       "     'languageCode': 'en'},\n",
       "    'authorAttribution': {'displayName': 'De Gao',\n",
       "     'uri': 'https://www.google.com/maps/contrib/113946997113206769266/reviews',\n",
       "     'photoUri': 'https://lh3.googleusercontent.com/a/ACg8ocKPGVLcaOTaOlI9FoT5Di6sqIBvi0Rh2DOQlOteYSsG=s128-c0x00000000-cc-rp-mo-ba6'},\n",
       "    'publishTime': '2022-03-19T17:53:34Z'},\n",
       "   {'name': 'places/ChIJGXeLPyhawokRXK9zCnvTMuQ/reviews/ChdDSUhNMG9nS0VJQ0FnSURzbnFEQXRBRRAB',\n",
       "    'relativePublishTimeDescription': '3 years ago',\n",
       "    'rating': 5,\n",
       "    'text': {'text': 'I love Rong Hang for the taste and sizable portion that the very affordable price gives you (at least for lunch special). I really enjoy their noodle soups ($7 for yellow fish noodle soup, $6 for oxtail noodle soup).They have live seafood prepared fresh; the menu items are a lot more expensive though. They have many lazy susan round tables that can fit large parties of ~10+. Not too busy during lunch weekdays.',\n",
       "     'languageCode': 'en'},\n",
       "    'originalText': {'text': 'I love Rong Hang for the taste and sizable portion that the very affordable price gives you (at least for lunch special). I really enjoy their noodle soups ($7 for yellow fish noodle soup, $6 for oxtail noodle soup).They have live seafood prepared fresh; the menu items are a lot more expensive though. They have many lazy susan round tables that can fit large parties of ~10+. Not too busy during lunch weekdays.',\n",
       "     'languageCode': 'en'},\n",
       "    'authorAttribution': {'displayName': 'Newstein Chang',\n",
       "     'uri': 'https://www.google.com/maps/contrib/103441440719784962925/reviews',\n",
       "     'photoUri': 'https://lh3.googleusercontent.com/a-/ALV-UjUs1iFaDSjQaNLTQTCQrOpExWdXOeq5wt7x3iA6ZOB8-wOk=s128-c0x00000000-cc-rp-mo-ba4'},\n",
       "    'publishTime': '2020-03-04T22:53:44Z'}]}]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Iterate over each row of the inspections_df DataFrame\n",
    "for index, row in inspections_df.iterrows():\n",
    "    # Construct the text query using dba, street, and zipcode\n",
    "    text_query = f\"{row['dba']} {row['street']}\"\n",
    "    if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "        text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "\n",
    "    # Define the query\n",
    "    data = {\n",
    "        'textQuery': text_query\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json().get('places', [])\n",
    "        \n",
    "        # Append the result along with the camis value to the results list\n",
    "        for place in places_data:\n",
    "            results.append({\n",
    "                'camis': row['camis'],\n",
    "                'place_id': place.get('id', ''),\n",
    "                'display_name': place.get('displayName', ''),\n",
    "                'formatted_address': place.get('formattedAddress', ''),\n",
    "                'reviews': place.get('reviews', [])\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the first few rows of the results DataFrame\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize empty lists to store the results for places and reviews\n",
    "places_results = []\n",
    "reviews_results = []\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Iterate over each row of the inspections_df DataFrame\n",
    "for index, row in inspections_df.iloc[2:3].iterrows():\n",
    "    # Construct the text query using dba, street, and zipcode\n",
    "    text_query = f\"{row['dba']} {row['street']}\"\n",
    "    if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "        text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "\n",
    "    # Define the query\n",
    "    data = {\n",
    "        'textQuery': text_query\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json().get('places', [])\n",
    "        \n",
    "        # Append the place details and reviews to the respective lists\n",
    "        for place in places_data:\n",
    "            places_results.append({\n",
    "                'camis': row['camis'],\n",
    "                'place_id': place.get('id', ''),\n",
    "                'display_name': place.get('displayName', ''),\n",
    "                'formatted_address': place.get('formattedAddress', '')\n",
    "            })\n",
    "            for review in place.get('reviews', []):\n",
    "                reviews_results.append({\n",
    "                    'camis': row['camis'],\n",
    "                    'place_id': place.get('id', ''),\n",
    "                    'review': review  # Assuming 'review' contains the review details\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n",
    "\n",
    "# Convert the results lists to DataFrames\n",
    "places_df = pd.DataFrame(places_results)\n",
    "reviews_df = pd.DataFrame(reviews_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize empty lists to store the results for places and reviews\n",
    "places_results = []\n",
    "reviews_results = []\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Iterate over each row of the inspections_df DataFrame\n",
    "for index, row in inspections_df.iloc[2:3].iterrows():\n",
    "    # Construct the text query using dba, street, and zipcode\n",
    "    text_query = f\"{row['dba']} {row['street']}\"\n",
    "    if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "        text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "\n",
    "    # Define the query\n",
    "    data = {\n",
    "        'textQuery': text_query\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json().get('places', [])\n",
    "        \n",
    "        # Append the place details and reviews to the respective lists\n",
    "        for place in places_data:\n",
    "            places_results.append({\n",
    "                'camis': row['camis'],\n",
    "                'place_id': place.get('id', ''),\n",
    "                'display_name': place.get('displayName', {}).get('text', ''),\n",
    "                'formatted_address': place.get('formattedAddress', '')\n",
    "            })\n",
    "            for review in place.get('reviews', []):\n",
    "                reviews_results.append({\n",
    "                    'camis': row['camis'],\n",
    "                    'place_id': place.get('id', ''),\n",
    "                    'review_name': review.get('name', ''),\n",
    "                    'review_relative_time': review.get('relativePublishTimeDescription', ''),\n",
    "                    'review_rating': review.get('rating', ''),\n",
    "                    'review_text': review.get('text', {}).get('text', ''),\n",
    "                    'review_language': review.get('text', {}).get('languageCode', ''),\n",
    "                    'author_display_name': review.get('authorAttribution', {}).get('displayName', ''),\n",
    "                    'author_uri': review.get('authorAttribution', {}).get('uri', ''),\n",
    "                    'author_photo_uri': review.get('authorAttribution', {}).get('photoUri', ''),\n",
    "                    'publish_time': review.get('publishTime', '')\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n",
    "\n",
    "# Convert the results lists to DataFrames\n",
    "places_df = pd.DataFrame(places_results)\n",
    "reviews_df = pd.DataFrame(reviews_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>dba</th>\n",
       "      <th>boro</th>\n",
       "      <th>building</th>\n",
       "      <th>street</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>phone</th>\n",
       "      <th>cuisine_description</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>action</th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_description</th>\n",
       "      <th>critical_flag</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade_date</th>\n",
       "      <th>record_date</th>\n",
       "      <th>inspection_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>community_board</th>\n",
       "      <th>council_district</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>nta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50129821</td>\n",
       "      <td>MEI JUNG MEI CHINESE RESTAURANT</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>1402</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>11210.0</td>\n",
       "      <td>9292509943</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04L</td>\n",
       "      <td>Evidence of mice or live mice in establishment...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>18.0</td>\n",
       "      <td>B</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Pre-permit (Operational) / Re-inspection</td>\n",
       "      <td>40.63638</td>\n",
       "      <td>-73.951435</td>\n",
       "      <td>314.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>77000.0</td>\n",
       "      <td>3120854.0</td>\n",
       "      <td>3.052260e+09</td>\n",
       "      <td>BK42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      camis                              dba      boro building  \\\n",
       "2  50129821  MEI JUNG MEI CHINESE RESTAURANT  Brooklyn     1402   \n",
       "\n",
       "            street  zipcode       phone cuisine_description  \\\n",
       "2  FLATBUSH AVENUE  11210.0  9292509943             Chinese   \n",
       "\n",
       "           inspection_date                                           action  \\\n",
       "2  2023-01-03T00:00:00.000  Violations were cited in the following area(s).   \n",
       "\n",
       "  violation_code                              violation_description  \\\n",
       "2            04L  Evidence of mice or live mice in establishment...   \n",
       "\n",
       "  critical_flag  score grade               grade_date  \\\n",
       "2      Critical   18.0     B  2023-01-03T00:00:00.000   \n",
       "\n",
       "               record_date                           inspection_type  \\\n",
       "2  2023-10-24T06:00:07.000  Pre-permit (Operational) / Re-inspection   \n",
       "\n",
       "   latitude  longitude  community_board  council_district  census_tract  \\\n",
       "2  40.63638 -73.951435            314.0              45.0       77000.0   \n",
       "\n",
       "         bin           bbl   nta  \n",
       "2  3120854.0  3.052260e+09  BK42  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspections_df.iloc[2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>place_id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>formatted_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>Goop li asian love food</td>\n",
       "      <td>1402 Flatbush Ave, Brooklyn, NY 11210, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      camis                     place_id             display_name  \\\n",
       "0  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE  Goop li asian love food   \n",
       "\n",
       "                            formatted_address  \n",
       "0  1402 Flatbush Ave, Brooklyn, NY 11210, USA  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goop li asian love food'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_df.display_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>place_id</th>\n",
       "      <th>review_name</th>\n",
       "      <th>review_relative_time</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_language</th>\n",
       "      <th>author_display_name</th>\n",
       "      <th>author_uri</th>\n",
       "      <th>author_photo_uri</th>\n",
       "      <th>publish_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>4</td>\n",
       "      <td>I used to go there all the time. Used to get d...</td>\n",
       "      <td>en</td>\n",
       "      <td>alwaysarcastic**</td>\n",
       "      <td>https://www.google.com/maps/contrib/1017042546...</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/ALV-UjWrF...</td>\n",
       "      <td>2022-10-20T10:55:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...</td>\n",
       "      <td>4 months ago</td>\n",
       "      <td>4</td>\n",
       "      <td>A lot of love for them. They are good on most ...</td>\n",
       "      <td>en</td>\n",
       "      <td>James Perkins</td>\n",
       "      <td>https://www.google.com/maps/contrib/1172583623...</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/ALV-UjXLp...</td>\n",
       "      <td>2023-06-19T13:10:41Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>3</td>\n",
       "      <td>This fried rice is always always always over c...</td>\n",
       "      <td>en</td>\n",
       "      <td>T J</td>\n",
       "      <td>https://www.google.com/maps/contrib/1121607201...</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/ALV-UjWv7...</td>\n",
       "      <td>2022-06-13T16:17:06Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...</td>\n",
       "      <td>10 months ago</td>\n",
       "      <td>5</td>\n",
       "      <td>Best fries and green plantain with wings they ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Melissa</td>\n",
       "      <td>https://www.google.com/maps/contrib/1175674079...</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/ALV-UjWbf...</td>\n",
       "      <td>2022-12-06T20:40:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/ChZ...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>5</td>\n",
       "      <td>One of the best places for Chinese food in the...</td>\n",
       "      <td>en</td>\n",
       "      <td>Asya Stepnova</td>\n",
       "      <td>https://www.google.com/maps/contrib/1102620964...</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/ALV-UjWgg...</td>\n",
       "      <td>2020-08-24T01:10:36Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      camis                     place_id  \\\n",
       "0  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "1  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "2  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "3  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "4  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "\n",
       "                                         review_name review_relative_time  \\\n",
       "0  places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...           a year ago   \n",
       "1  places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...         4 months ago   \n",
       "2  places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...           a year ago   \n",
       "3  places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/Chd...        10 months ago   \n",
       "4  places/ChIJVQB8JUxbwokRB2EYAqesQvE/reviews/ChZ...          3 years ago   \n",
       "\n",
       "   review_rating                                        review_text  \\\n",
       "0              4  I used to go there all the time. Used to get d...   \n",
       "1              4  A lot of love for them. They are good on most ...   \n",
       "2              3  This fried rice is always always always over c...   \n",
       "3              5  Best fries and green plantain with wings they ...   \n",
       "4              5  One of the best places for Chinese food in the...   \n",
       "\n",
       "  review_language author_display_name  \\\n",
       "0              en    alwaysarcastic**   \n",
       "1              en       James Perkins   \n",
       "2              en                 T J   \n",
       "3              en             Melissa   \n",
       "4              en       Asya Stepnova   \n",
       "\n",
       "                                          author_uri  \\\n",
       "0  https://www.google.com/maps/contrib/1017042546...   \n",
       "1  https://www.google.com/maps/contrib/1172583623...   \n",
       "2  https://www.google.com/maps/contrib/1121607201...   \n",
       "3  https://www.google.com/maps/contrib/1175674079...   \n",
       "4  https://www.google.com/maps/contrib/1102620964...   \n",
       "\n",
       "                                    author_photo_uri          publish_time  \n",
       "0  https://lh3.googleusercontent.com/a-/ALV-UjWrF...  2022-10-20T10:55:46Z  \n",
       "1  https://lh3.googleusercontent.com/a-/ALV-UjXLp...  2023-06-19T13:10:41Z  \n",
       "2  https://lh3.googleusercontent.com/a-/ALV-UjWv7...  2022-06-13T16:17:06Z  \n",
       "3  https://lh3.googleusercontent.com/a-/ALV-UjWbf...  2022-12-06T20:40:59Z  \n",
       "4  https://lh3.googleusercontent.com/a-/ALV-UjWgg...  2020-08-24T01:10:36Z  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com/maps/contrib/101704254655317829682/reviews'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.author_uri[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display the first few rows of the Places and Reviews DataFrames\n",
    "print(\"Places DataFrame:\")\n",
    "print(places_df.head())\n",
    "print(\"\\nReviews DataFrame:\")\n",
    "print(reviews_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize empty lists to store the results for places and reviews\n",
    "places_results = []\n",
    "reviews_results = []\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Iterate over each row of the inspections_df DataFrame\n",
    "for index, row in inspections_df.iloc[2:3].iterrows():\n",
    "    # Construct the text query using dba, street, and zipcode\n",
    "    text_query = f\"{row['dba']} {row['street']}\"\n",
    "    if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "        text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "\n",
    "    # Define the query\n",
    "    data = {\n",
    "        'textQuery': text_query\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json().get('places', [])\n",
    "        \n",
    "        # Append the place details and reviews to the respective lists\n",
    "        for place in places_data:\n",
    "            places_results.append({\n",
    "                'camis': row['camis'],\n",
    "                'place_id': place.get('id', ''),\n",
    "                'display_name': place.get('displayName', {}).get('text', ''),\n",
    "                'formatted_address': place.get('formattedAddress', '')\n",
    "            })\n",
    "            for review in place.get('reviews', []):\n",
    "                # Extract the unique review identifier\n",
    "                review_id = review.get('name', '').split('/')[-1]\n",
    "                # Extract the unique contributor ID from the author_uri\n",
    "                contributor_id = review.get('authorAttribution', {}).get('uri', '').split('/')[-2]\n",
    "                reviews_results.append({\n",
    "                    'camis': row['camis'],\n",
    "                    'place_id': place.get('id', ''),\n",
    "                    'review_id': review_id,\n",
    "                    # 'review_relative_time': review.get('relativePublishTimeDescription', ''),\n",
    "                    'review_rating': review.get('rating', ''),\n",
    "                    'review_text': review.get('text', {}).get('text', ''),\n",
    "                    'review_language': review.get('text', {}).get('languageCode', ''),\n",
    "                    # 'author_display_name': review.get('authorAttribution', {}).get('displayName', ''),\n",
    "                    'contributor_id': contributor_id,\n",
    "                    # 'author_photo_uri': review.get('authorAttribution', {}).get('photoUri', ''),\n",
    "                    'publish_time': review.get('publishTime', '')\n",
    "                })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n",
    "\n",
    "# Convert the results lists to DataFrames\n",
    "places_df = pd.DataFrame(places_results)\n",
    "reviews_df = pd.DataFrame(reviews_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'textQuery': 'MEI JUNG MEI CHINESE RESTAURANT FLATBUSH AVENUE 11210'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>place_id</th>\n",
       "      <th>display_name</th>\n",
       "      <th>formatted_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>Goop li asian love food</td>\n",
       "      <td>1402 Flatbush Ave, Brooklyn, NY 11210, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      camis                     place_id             display_name  \\\n",
       "0  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE  Goop li asian love food   \n",
       "\n",
       "                            formatted_address  \n",
       "0  1402 Flatbush Ave, Brooklyn, NY 11210, USA  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Goop li asian love food'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "places_df.display_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>place_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>review_rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_language</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>publish_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURlMjZXOGpBRRAB</td>\n",
       "      <td>4</td>\n",
       "      <td>I used to go there all the time. Used to get d...</td>\n",
       "      <td>en</td>\n",
       "      <td>101704254655317829682</td>\n",
       "      <td>2022-10-20T10:55:46Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNKOE56TTR3RRAB</td>\n",
       "      <td>4</td>\n",
       "      <td>A lot of love for them. They are good on most ...</td>\n",
       "      <td>en</td>\n",
       "      <td>117258362311722126898</td>\n",
       "      <td>2023-06-19T13:10:41Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUR5a3RPVjN3RRAB</td>\n",
       "      <td>3</td>\n",
       "      <td>This fried rice is always always always over c...</td>\n",
       "      <td>en</td>\n",
       "      <td>112160720159424315379</td>\n",
       "      <td>2022-06-13T16:17:06Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUQtN2ZyVXZ3RRAB</td>\n",
       "      <td>5</td>\n",
       "      <td>Best fries and green plantain with wings they ...</td>\n",
       "      <td>en</td>\n",
       "      <td>117567407903896857593</td>\n",
       "      <td>2022-12-06T20:40:59Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50129821</td>\n",
       "      <td>ChIJVQB8JUxbwokRB2EYAqesQvE</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNDM3NMdFlnEAE</td>\n",
       "      <td>5</td>\n",
       "      <td>One of the best places for Chinese food in the...</td>\n",
       "      <td>en</td>\n",
       "      <td>110262096475130641021</td>\n",
       "      <td>2020-08-24T01:10:36Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      camis                     place_id  \\\n",
       "0  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "1  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "2  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "3  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "4  50129821  ChIJVQB8JUxbwokRB2EYAqesQvE   \n",
       "\n",
       "                              review_id  review_rating  \\\n",
       "0  ChdDSUhNMG9nS0VJQ0FnSURlMjZXOGpBRRAB              4   \n",
       "1  ChdDSUhNMG9nS0VJQ0FnSUNKOE56TTR3RRAB              4   \n",
       "2  ChdDSUhNMG9nS0VJQ0FnSUR5a3RPVjN3RRAB              3   \n",
       "3  ChdDSUhNMG9nS0VJQ0FnSUQtN2ZyVXZ3RRAB              5   \n",
       "4   ChZDSUhNMG9nS0VJQ0FnSUNDM3NMdFlnEAE              5   \n",
       "\n",
       "                                         review_text review_language  \\\n",
       "0  I used to go there all the time. Used to get d...              en   \n",
       "1  A lot of love for them. They are good on most ...              en   \n",
       "2  This fried rice is always always always over c...              en   \n",
       "3  Best fries and green plantain with wings they ...              en   \n",
       "4  One of the best places for Chinese food in the...              en   \n",
       "\n",
       "          contributor_id          publish_time  \n",
       "0  101704254655317829682  2022-10-20T10:55:46Z  \n",
       "1  117258362311722126898  2023-06-19T13:10:41Z  \n",
       "2  112160720159424315379  2022-06-13T16:17:06Z  \n",
       "3  117567407903896857593  2022-12-06T20:40:59Z  \n",
       "4  110262096475130641021  2020-08-24T01:10:36Z  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize empty lists to store the results for places, reviews, and API logs\n",
    "places_results = []\n",
    "reviews_results = []\n",
    "api_logs = []\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Parameters for saving progress\n",
    "save_interval = 10  # Save after every 10 rows\n",
    "current_row = 0\n",
    "\n",
    "# Iterate over each row of the inspections_df DataFrame\n",
    "for index, row in inspections_df.iloc[39:40].iterrows():\n",
    "    current_row += 1\n",
    "    # Construct the text query using dba, building, street, borough, and zipcode\n",
    "    text_query = f\"{row['dba']} {row['building']} {row['street']} {row['boro']}\"\n",
    "    if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "        text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "    if pd.notnull(row['phone']):  # Check if the phone number is not null\n",
    "        text_query += f\" {row['phone']}\"  # Append the phone number to the query\n",
    "    if pd.notnull(row['cuisine_description']):  # Check if the cuisine type is not null\n",
    "        text_query += f\" {row['cuisine_description']}\"  # Append the cuisine type to the query\n",
    "\n",
    "    # Define the query\n",
    "    data = {\n",
    "        'textQuery': text_query\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json().get('places', [])\n",
    "        \n",
    "        # Append the place details and reviews to the respective lists\n",
    "        for place in places_data:\n",
    "            display_name = place.get('displayName', {}).get('text', '')\n",
    "            formatted_address = place.get('formattedAddress', '')\n",
    "            places_results.append({\n",
    "                'camis': row['camis'],\n",
    "                'place_id': place.get('id', ''),\n",
    "                'display_name': display_name,\n",
    "                'formatted_address': formatted_address\n",
    "            })\n",
    "            for review in place.get('reviews', []):\n",
    "                # Extract the unique review identifier and contributor ID\n",
    "                review_id = review.get('name', '').split('/')[-1]\n",
    "                contributor_id = review.get('authorAttribution', {}).get('uri', '').split('/')[-2]\n",
    "                reviews_results.append({\n",
    "                    'camis': row['camis'],\n",
    "                    'place_id': place.get('id', ''),\n",
    "                    'review_id': review_id,\n",
    "                    'review_relative_time': review.get('relativePublishTimeDescription', ''),\n",
    "                    'review_rating': review.get('rating', ''),\n",
    "                    'review_text': review.get('text', {}).get('text', ''),\n",
    "                    'review_language': review.get('text', {}).get('languageCode', ''),\n",
    "                    'author_display_name': review.get('authorAttribution', {}).get('displayName', ''),\n",
    "                    'contributor_id': contributor_id,\n",
    "                    'author_photo_uri': review.get('authorAttribution', {}).get('photoUri', ''),\n",
    "                    'publish_time': review.get('publishTime', '')\n",
    "                })\n",
    "            # Log the API call with display_name and formatted_address\n",
    "            api_logs.append({\n",
    "                'row_number': current_row,\n",
    "                'query': text_query,\n",
    "                'status_code': response.status_code,\n",
    "                'display_name': display_name,\n",
    "                'formatted_address': formatted_address\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n",
    "        api_logs.append({\n",
    "            'row_number': current_row,\n",
    "            'query': text_query,\n",
    "            'status_code': response.status_code,\n",
    "            'display_name': '',\n",
    "            'formatted_address': ''\n",
    "        })\n",
    "\n",
    "    # Save progress at regular intervals\n",
    "    if current_row % save_interval == 0:\n",
    "        pd.DataFrame(places_results).to_csv('places_progress.csv', index=False)\n",
    "        pd.DataFrame(reviews_results).to_csv('reviews_progress.csv', index=False)\n",
    "        pd.DataFrame(api_logs).to_csv('api_log_progress.csv', index=False)\n",
    "\n",
    "# Save the final results\n",
    "pd.DataFrame(places_results).to_csv('places_final.csv', index=False)\n",
    "pd.DataFrame(reviews_results).to_csv('reviews_final.csv', index=False)\n",
    "pd.DataFrame(api_logs).to_csv('api_log_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>camis</th>\n",
       "      <th>dba</th>\n",
       "      <th>boro</th>\n",
       "      <th>building</th>\n",
       "      <th>street</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>phone</th>\n",
       "      <th>cuisine_description</th>\n",
       "      <th>inspection_date</th>\n",
       "      <th>action</th>\n",
       "      <th>violation_code</th>\n",
       "      <th>violation_description</th>\n",
       "      <th>critical_flag</th>\n",
       "      <th>score</th>\n",
       "      <th>grade</th>\n",
       "      <th>grade_date</th>\n",
       "      <th>record_date</th>\n",
       "      <th>inspection_type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>community_board</th>\n",
       "      <th>council_district</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>nta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>50099824</td>\n",
       "      <td>INDIA HOUSE</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>586</td>\n",
       "      <td>NOSTRAND AVENUE</td>\n",
       "      <td>11216.0</td>\n",
       "      <td>7188577011</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Establishment Closed by DOHMH. Violations were...</td>\n",
       "      <td>06E</td>\n",
       "      <td>Sanitized equipment or utensil, including in-u...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "      <td>40.678687</td>\n",
       "      <td>-73.949677</td>\n",
       "      <td>303.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>24700.0</td>\n",
       "      <td>3053936.0</td>\n",
       "      <td>3.018660e+09</td>\n",
       "      <td>BK61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>50106021</td>\n",
       "      <td>TAMMAM CAFE</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>735</td>\n",
       "      <td>NOSTRAND AVENUE</td>\n",
       "      <td>11216.0</td>\n",
       "      <td>3477894734</td>\n",
       "      <td>Coffee/Tea</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04A</td>\n",
       "      <td>Food Protection Certificate (FPC) not held by ...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>10.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "      <td>40.672147</td>\n",
       "      <td>-73.950277</td>\n",
       "      <td>308.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>31702.0</td>\n",
       "      <td>3031915.0</td>\n",
       "      <td>3.012480e+09</td>\n",
       "      <td>BK61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>50003774</td>\n",
       "      <td>GOLDEN KRUST CARIBBEAN BAKERY &amp; GRILL</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>4108</td>\n",
       "      <td>FARRAGUT ROAD</td>\n",
       "      <td>11210.0</td>\n",
       "      <td>7185766021</td>\n",
       "      <td>Caribbean</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Violations were cited in the following area(s).</td>\n",
       "      <td>04L</td>\n",
       "      <td>Evidence of mice or live mice in establishment...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Initial Inspection</td>\n",
       "      <td>40.636919</td>\n",
       "      <td>-73.937311</td>\n",
       "      <td>317.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>83600.0</td>\n",
       "      <td>3114504.0</td>\n",
       "      <td>3.050160e+09</td>\n",
       "      <td>BK91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>50076302</td>\n",
       "      <td>PAPA JOHN'S</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>2241</td>\n",
       "      <td>WESTCHESTER AVENUE</td>\n",
       "      <td>10462.0</td>\n",
       "      <td>7185977272</td>\n",
       "      <td>Pizza</td>\n",
       "      <td>2023-01-03T00:00:00.000</td>\n",
       "      <td>Establishment Closed by DOHMH. Violations were...</td>\n",
       "      <td>06D</td>\n",
       "      <td>Food contact surface not properly washed, rins...</td>\n",
       "      <td>Critical</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-10-24T06:00:07.000</td>\n",
       "      <td>Cycle Inspection / Re-inspection</td>\n",
       "      <td>40.834317</td>\n",
       "      <td>-73.850571</td>\n",
       "      <td>210.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20601.0</td>\n",
       "      <td>2041407.0</td>\n",
       "      <td>2.039630e+09</td>\n",
       "      <td>BX59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       camis                                    dba      boro building  \\\n",
       "38  50099824                            INDIA HOUSE  Brooklyn      586   \n",
       "39  50106021                            TAMMAM CAFE  Brooklyn      735   \n",
       "40  50003774  GOLDEN KRUST CARIBBEAN BAKERY & GRILL  Brooklyn     4108   \n",
       "41  50076302                            PAPA JOHN'S     Bronx     2241   \n",
       "\n",
       "                street  zipcode       phone cuisine_description  \\\n",
       "38     NOSTRAND AVENUE  11216.0  7188577011              Indian   \n",
       "39     NOSTRAND AVENUE  11216.0  3477894734          Coffee/Tea   \n",
       "40       FARRAGUT ROAD  11210.0  7185766021           Caribbean   \n",
       "41  WESTCHESTER AVENUE  10462.0  7185977272               Pizza   \n",
       "\n",
       "            inspection_date  \\\n",
       "38  2023-01-03T00:00:00.000   \n",
       "39  2023-01-03T00:00:00.000   \n",
       "40  2023-01-03T00:00:00.000   \n",
       "41  2023-01-03T00:00:00.000   \n",
       "\n",
       "                                               action violation_code  \\\n",
       "38  Establishment Closed by DOHMH. Violations were...            06E   \n",
       "39    Violations were cited in the following area(s).            04A   \n",
       "40    Violations were cited in the following area(s).            04L   \n",
       "41  Establishment Closed by DOHMH. Violations were...            06D   \n",
       "\n",
       "                                violation_description critical_flag  score  \\\n",
       "38  Sanitized equipment or utensil, including in-u...      Critical   69.0   \n",
       "39  Food Protection Certificate (FPC) not held by ...      Critical   10.0   \n",
       "40  Evidence of mice or live mice in establishment...      Critical   14.0   \n",
       "41  Food contact surface not properly washed, rins...      Critical   56.0   \n",
       "\n",
       "   grade               grade_date              record_date  \\\n",
       "38   NaN                      NaN  2023-10-24T06:00:07.000   \n",
       "39     A  2023-01-03T00:00:00.000  2023-10-24T06:00:07.000   \n",
       "40   NaN                      NaN  2023-10-24T06:00:07.000   \n",
       "41   NaN                      NaN  2023-10-24T06:00:07.000   \n",
       "\n",
       "                          inspection_type   latitude  longitude  \\\n",
       "38       Cycle Inspection / Re-inspection  40.678687 -73.949677   \n",
       "39       Cycle Inspection / Re-inspection  40.672147 -73.950277   \n",
       "40  Cycle Inspection / Initial Inspection  40.636919 -73.937311   \n",
       "41       Cycle Inspection / Re-inspection  40.834317 -73.850571   \n",
       "\n",
       "    community_board  council_district  census_tract        bin           bbl  \\\n",
       "38            303.0              36.0       24700.0  3053936.0  3.018660e+09   \n",
       "39            308.0              35.0       31702.0  3031915.0  3.012480e+09   \n",
       "40            317.0              45.0       83600.0  3114504.0  3.050160e+09   \n",
       "41            210.0              18.0       20601.0  2041407.0  2.039630e+09   \n",
       "\n",
       "     nta  \n",
       "38  BK61  \n",
       "39  BK61  \n",
       "40  BK91  \n",
       "41  BX59  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspections_df.iloc[38:42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'ChIJy4EKcZ1bwokRAxycHPSTeSU',\n",
       "  'formattedAddress': '735 Nostrand Ave., Brooklyn, NY 11216, USA',\n",
       "  'displayName': {'text': '735 Nostrand Ave.'}}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json().get('places', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Initialize empty lists to store the results for places, reviews, and API logs\n",
    "places_results = []\n",
    "reviews_results = []\n",
    "api_logs = []\n",
    "\n",
    "# Define the URL and headers\n",
    "url = 'https://places.googleapis.com/v1/places:searchText'\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'X-Goog-Api-Key': g_places_api_key,\n",
    "    'X-Goog-FieldMask': 'places.id,places.displayName,places.formattedAddress,places.reviews'\n",
    "}\n",
    "\n",
    "# Parameters for saving progress\n",
    "save_interval = 10  # Save after every 10 rows\n",
    "current_row = 0\n",
    "\n",
    "# Iterate over each row of the inspections_df DataFrame\n",
    "for index, row in inspections_df.iloc[39:40].iterrows():\n",
    "    current_row += 1\n",
    "    # Construct the text query using dba, building, street, borough, and zipcode\n",
    "    text_query = f\"{row['dba']} {row['building']} {row['street']} {row['boro']}\"\n",
    "    if pd.notnull(row['zipcode']):  # Check if the zipcode is not null\n",
    "        text_query += f\" {int(row['zipcode'])}\"  # Append the zipcode to the query\n",
    "    if pd.notnull(row['phone']):  # Check if the phone number is not null\n",
    "        text_query += f\" {row['phone']}\"  # Append the phone number to the query\n",
    "    if pd.notnull(row['cuisine_description']):  # Check if the cuisine type is not null\n",
    "        text_query += f\" {row['cuisine_description']}\"  # Append the cuisine type to the query\n",
    "\n",
    "    # Define the query\n",
    "    data = {\n",
    "        'textQuery': text_query\n",
    "    }\n",
    "\n",
    "    # Make the POST request\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "\n",
    "    # Process the response\n",
    "    if response.status_code == 200:\n",
    "        places_data = response.json().get('places', [])\n",
    "        \n",
    "        # Append the place details and reviews to the respective lists\n",
    "        for place in places_data:\n",
    "            display_name = place.get('displayName', {}).get('text', '').strip()\n",
    "            formatted_address = place.get('formattedAddress', '').strip()\n",
    "            address_first_part = formatted_address.split(',')[0].strip()\n",
    "\n",
    "            # Check if the display name matches the first part of the formatted address\n",
    "            if display_name.lower() == address_first_part.lower():\n",
    "                note = 'Possible address only, no specific business match'\n",
    "            else:\n",
    "                note = ''\n",
    "                places_results.append({\n",
    "                    'camis': row['camis'],\n",
    "                    'place_id': place.get('id', ''),\n",
    "                    'display_name': display_name,\n",
    "                    'formatted_address': formatted_address\n",
    "                })\n",
    "\n",
    "                for review in place.get('reviews', []):\n",
    "                    # Extract the unique review identifier and contributor ID\n",
    "                    review_id = review.get('name', '').split('/')[-1]\n",
    "                    contributor_id = review.get('authorAttribution', {}).get('uri', '').split('/')[-2]\n",
    "                    reviews_results.append({\n",
    "                        'camis': row['camis'],\n",
    "                        'place_id': place.get('id', ''),\n",
    "                        'review_id': review_id,\n",
    "                        'review_relative_time': review.get('relativePublishTimeDescription', ''),\n",
    "                        'review_rating': review.get('rating', ''),\n",
    "                        'review_text': review.get('text', {}).get('text', ''),\n",
    "                        'review_language': review.get('text', {}).get('languageCode', ''),\n",
    "                        'author_display_name': review.get('authorAttribution', {}).get('displayName', ''),\n",
    "                        'contributor_id': contributor_id,\n",
    "                        'author_photo_uri': review.get('authorAttribution', {}).get('photoUri', ''),\n",
    "                        'publish_time': review.get('publishTime', '')\n",
    "                    })\n",
    "\n",
    "            # Log the API call with display_name, formatted_address, and note\n",
    "            api_logs.append({\n",
    "                'row_number': current_row,\n",
    "                'query': text_query,\n",
    "                'status_code': response.status_code,\n",
    "                'display_name': display_name,\n",
    "                'formatted_address': formatted_address,\n",
    "                'note': note\n",
    "            })\n",
    "    else:\n",
    "        print(f\"Failed to retrieve data for {text_query}: {response.status_code}\")\n",
    "        api_logs.append({\n",
    "            'row_number': current_row,\n",
    "            'query': text_query,\n",
    "            'status_code': response.status_code,\n",
    "            'display_name': '',\n",
    "            'formatted_address': '',\n",
    "            'note': 'API call failed'\n",
    "        })\n",
    "\n",
    "    # Save progress at regular intervals\n",
    "    if current_row % save_interval == 0:\n",
    "        pd.DataFrame(places_results).to_csv('places_progress.csv', index=False)\n",
    "        pd.DataFrame(reviews_results).to_csv('reviews_progress.csv', index=False)\n",
    "        pd.DataFrame(api_logs).to_csv('api_log_progress.csv', index=False)\n",
    "\n",
    "# Save the final results\n",
    "pd.DataFrame(places_results).to_csv('places_final.csv', index=False)\n",
    "pd.DataFrame(reviews_results).to_csv('reviews_final.csv', index=False)\n",
    "pd.DataFrame(api_logs).to_csv('api_log_final.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
