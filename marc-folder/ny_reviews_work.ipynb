{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2079005-1150-4502-bf89-c1e75c4ad5d1",
   "metadata": {},
   "source": [
    "# Marc Model Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d5b1644-5a92-45b6-9145-48c1885fb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire as a\n",
    "import prepare as p\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc80ab2b-1d2a-44aa-bee5-7fb53b4c7068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ny_reviews.csv found!\n"
     ]
    }
   ],
   "source": [
    "ny_reviews = p.acquire_ny_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b983ddb6-110b-4a7b-8e09-e7ad2a655589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ny_reviews = ny_reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfed25d3-b875-4b85-90da-85873092cdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4086 entries, 155 to 59922\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   camis                  4086 non-null   int64  \n",
      " 1   dba                    4086 non-null   object \n",
      " 2   boro                   4086 non-null   object \n",
      " 3   phone                  4086 non-null   int64  \n",
      " 4   cuisine_description    4086 non-null   object \n",
      " 5   inspection_date        4086 non-null   object \n",
      " 6   action                 4086 non-null   object \n",
      " 7   score                  4086 non-null   int64  \n",
      " 8   grade                  4086 non-null   object \n",
      " 9   latitude               4086 non-null   float64\n",
      " 10  longitude              4086 non-null   float64\n",
      " 11  full_address           4086 non-null   object \n",
      " 12  violation_code         4086 non-null   object \n",
      " 13  violation_description  4086 non-null   object \n",
      " 14  last_inspection_date   4086 non-null   object \n",
      " 15  concatenated_reviews   4086 non-null   object \n",
      "dtypes: float64(2), int64(3), object(11)\n",
      "memory usage: 542.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ny_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db0a59d-5968-4d6a-b5f3-8117627463df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grade\n",
       "A    2402\n",
       "B     975\n",
       "C     709\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_reviews.grade.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe7abb0-c885-4634-9989-28aae4312049",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_reviews = ny_reviews[['grade', 'concatenated_reviews']]\n",
    "ny_reviews = ny_reviews.rename(columns={'concatenated_reviews': 'reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c49c57f-f868-4b59-a14a-2c2c88318384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>C</td>\n",
       "      <td>Very authentic place. To the point that I ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>B</td>\n",
       "      <td>Really great classic Chinese comfort food. Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>C</td>\n",
       "      <td>Great spot cheap eats Didn’t have time to take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>C</td>\n",
       "      <td>Great Place for some Home Cooking Friendly a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>C</td>\n",
       "      <td>Great dim sum cafe open early!!  Popular place...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    grade                                            reviews\n",
       "155     C    Very authentic place. To the point that I ne...\n",
       "156     B  Really great classic Chinese comfort food. Gre...\n",
       "157     C  Great spot cheap eats Didn’t have time to take...\n",
       "158     C    Great Place for some Home Cooking Friendly a...\n",
       "159     C  Great dim sum cafe open early!!  Popular place..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96500e49-b5c3-4b8c-b72c-43dd3be44729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4086 entries, 155 to 59922\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   grade    4086 non-null   object\n",
      " 1   reviews  4086 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 95.8+ KB\n"
     ]
    }
   ],
   "source": [
    "ny_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe6c06-97ce-4193-9176-da723db4e57f",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d49610-b15c-424c-909d-03479febbbd7",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00a7b6-b0db-4643-b1f7-f5310d5f7e93",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449786f6-5198-4fdc-b0d6-a82e9346a33c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077769b5-eb61-4500-bb48-140be2a89fbe",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2751d8c-f85e-4ab2-9f32-e0431238c8b6",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d01aa-5b59-4df6-9c99-27e08998891c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d4141-60b6-4344-9e42-4c79a9014b78",
   "metadata": {},
   "source": [
    "## Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d42547-bb68-4061-ba01-526b4f2c9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.metrics import classification_report as class_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c1a5c43-4be1-4eff-862e-a2c831a50ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade', 'reviews']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_reviews.columns.to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80adcb6-d492-46ea-80b0-7436b9914bc5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb33d5-83be-4c09-86c9-5880b741a696",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5642462-2684-4eb9-8c62-19634f12cecb",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc5829-6111-4769-9e3f-07b067ffc181",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bfe33-59db-41e5-b45d-b48d3b0ca74b",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c4e1bed-f843-481e-892b-fbb7a10bf967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline():\n",
    "\n",
    "    # Load and preprocess your data\n",
    "    ny_reviews = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    ny_reviews = ny_reviews.rename(columns={'concatenated_reviews': 'reviews'})\n",
    "    ny_reviews = ny_reviews.dropna()\n",
    "    \n",
    "    X = ny_reviews.reviews\n",
    "    y = ny_reviews.grade\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    train_baseline_acc = y_train.value_counts().max() / y_train.shape[0] * 100    \n",
    "    val_baseline_acc = y_val.value_counts().max() / y_val.shape[0] * 100\n",
    "\n",
    "    print(f'\\nBaseline Accuracy')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\n\\nTrain baseline accuracy: {round(train_baseline_acc)}%\\n')\n",
    "    print(f'\\nValidation baseline accuracy: {round(val_baseline_acc)}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38a0c1ed-ee78-4a1d-92bc-f0116b9be3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Baseline Accuracy\n",
      "==================================================\n",
      "\n",
      "\n",
      "Train baseline accuracy: 59%\n",
      "\n",
      "\n",
      "Validation baseline accuracy: 62%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11525e0-a6b8-4631-a6bd-e2865f45aff7",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51873dc5-4b6f-43d0-8670-a75d3d5a66c2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42dfa3-bbe5-4167-8a6b-53b1dd20c299",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653b80d-6b9c-44d2-85d2-9e040eaf2f44",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741d388-6df5-4078-a603-5ebea0a843af",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2230d-4fac-486c-bfb3-4c2b9c6cd92d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e0f73-6c93-4690-bd72-69e7927f14e2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48a816d2-7ceb-4dc7-94a5-f222fa6d7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    # Load and preprocess your data\n",
    "    ny_reviews = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    ny_reviews = ny_reviews.rename(columns={'concatenated_reviews': 'reviews'})\n",
    "    ny_reviews = ny_reviews.dropna()\n",
    "\n",
    "    X = ny_reviews.reviews # add new features here\n",
    "    y = ny_reviews.grade\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create TF-IDF vectors\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    lm = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        C=1.0,\n",
    "        fit_intercept=False,\n",
    "        class_weight='balanced',\n",
    "        solver='liblinear',\n",
    "        max_iter=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    lm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': lm.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': lm.predict(X_val_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "\n",
    "    print(f'\\nLogisitic Regression Model (Hyperparameters Used)')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30e05bce-df5e-41bd-9595-6d775b458d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logisitic Regression Model (Hyperparameters Used)\n",
      "==================================================\n",
      "\n",
      "Train Accuracy: 0.81\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5074f-d90c-4515-ab78-8c2447f85a36",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c937631-a452-4af7-8ffc-6e97d805fae5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdbdd7-f435-440d-9b38-5ff37f26312e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d0095-588b-412c-9a02-242cc4e6464c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc2dcd-b767-4c06-ab10-1136da9878de",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c14db-2de3-454a-b577-d0baeef07ba8",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f621517-eb32-4551-bac2-9c83a75438b2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df32f929-2856-4e8d-baf4-9c99bdb5b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    # Load and preprocess your data\n",
    "    ny_reviews = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    ny_reviews = ny_reviews.rename(columns={'concatenated_reviews': 'reviews'})\n",
    "    ny_reviews = ny_reviews.dropna()\n",
    "\n",
    "    X = ny_reviews.reviews # add new features\n",
    "    y = ny_reviews.grade\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create TF-IDF vectors\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    # Train KNN Model\n",
    "    knn = KNeighborsClassifier(\n",
    "    n_neighbors=2,  \n",
    "    weights='distance',  # distance\n",
    "    p=2,  # Euclidean distance\n",
    "    algorithm='auto',  # 'ball_tree', 'kd_tree', or 'brute'\n",
    "    leaf_size=30,  \n",
    "    metric='euclidean'  # You can choose other metrics or provide custom ones\n",
    "    )\n",
    "    knn.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': knn.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': knn.predict(X_val_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "\n",
    "    print(f'\\nKNearest Neighbors (Hyperparameters Used)')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "684a17b9-c2ab-4513-bd41-3eff13aeec97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNearest Neighbors (Hyperparameters Used)\n",
      "==================================================\n",
      "\n",
      "Train Accuracy: 0.99\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fed37c-03be-4ef4-9e33-645a33400131",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368134e-2789-4cc2-ae15-4f22e966b16d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c25bcd-ffda-49ea-906a-00d22e96098e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac656c-e4a1-4aef-9821-b5038372e349",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f491ba5-7456-43fa-9620-efb838780668",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e373719d-29d7-47d1-b41a-bb026e960e27",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209798a-a32b-4bc8-98c9-efb88154c39e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2cff40f-fbc0-4673-b5d0-4f11ba5d5b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def model_3():\n",
    "\n",
    "    # Load and preprocess your data\n",
    "    ny_reviews = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    ny_reviews = ny_reviews.rename(columns={'concatenated_reviews': 'reviews'})\n",
    "    ny_reviews = ny_reviews.dropna()\n",
    "    \n",
    "    # Initialize the label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Encode the target labels\n",
    "    y_encoded = label_encoder.fit_transform(ny_reviews.grade)\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(ny_reviews.reviews, y_encoded, train_size=0.7, random_state=42) # add new features\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Initialize and fit the TfidfVectorizer on the training data\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Create the XGBoost classifier instance\n",
    "    bst = XGBClassifier(n_estimators=100, max_depth=2, learning_rate=0.25, objective='multi:softprob', num_class=len(label_encoder.classes_))\n",
    "    \n",
    "    # Fit the XGBoost model on the training data\n",
    "    bst.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict the classes on the validation data\n",
    "    preds = bst.predict(X_val_tfidf)\n",
    "    \n",
    "    # If you want to decode the predicted labels back to their original class names:\n",
    "    preds_decoded = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': bst.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': bst.predict(X_val_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "\n",
    "    print(f'\\nXGBClassifier Model (Hyperparameters Used)')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "118fb11f-4f47-48dd-9c4f-291c9f37c152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier Model (Hyperparameters Used)\n",
      "==================================================\n",
      "\n",
      "Train Accuracy: 0.75\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dccc32-d3b4-4d75-bf32-29ac0d72385c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3655488-dfce-4a23-a432-7a8b9449878c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60263a-6d9d-4154-a054-25e6444682c2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a73a7-c14c-457a-99f0-a30fffb086c2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f768d0-f0a7-4ec2-b629-66ed52c3e216",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bc803-dc7e-46ec-8b17-31862e93e792",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b851ba-c91c-49ce-843e-c32994821e19",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e1f2918-defa-4bf5-b7ce-09434e035dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_4():\n",
    "    # Load and preprocess your data\n",
    "    ny_reviews = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    ny_reviews = ny_reviews.rename(columns={'concatenated_reviews': 'reviews'})\n",
    "    ny_reviews = ny_reviews.dropna()\n",
    "\n",
    "    X = ny_reviews.reviews # add new features\n",
    "    y = ny_reviews.grade\n",
    "\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create TF-IDF vectors\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    lm = LogisticRegression(\n",
    "    penalty='l2',  # L2 regularization (Ridge)\n",
    "    C=1.0,  # Inverse of regularization strength\n",
    "    fit_intercept=False,  # Include an intercept\n",
    "    class_weight='balanced',  # You can set class weights if needed\n",
    "    solver='liblinear',  # Choose a solver appropriate for your data\n",
    "    max_iter=100,  # You may need to increase this if the model doesn't converge\n",
    "    random_state=42  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    lm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': lm.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': lm.predict(X_val_tfidf)})\n",
    "    y_test_res = pd.DataFrame({'actual': y_test, 'preds': lm.predict(X_test_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "    test_accuracy = accuracy_score(y_test_res['actual'], y_test_res['preds'])\n",
    "\n",
    "    print(f'\\nFinal Model Logisitic Regression with Hyperparameter tuning')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')\n",
    "    print(f'\\nTest Accuracy: {test_accuracy:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c767d110-0c2b-4081-b88e-9828beff398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model Logisitic Regression with Hyperparameter tuning\n",
      "==================================================\n",
      "\n",
      "Train Accuracy: 0.81\n",
      "\n",
      "\n",
      "Validation Accuracy: 0.54\n",
      "\n",
      "\n",
      "Test Accuracy: 0.50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_4()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
