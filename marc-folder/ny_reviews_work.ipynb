{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2079005-1150-4502-bf89-c1e75c4ad5d1",
   "metadata": {},
   "source": [
    "# Marc Model Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d5b1644-5a92-45b6-9145-48c1885fb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire as a\n",
    "import prepare as p\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc80ab2b-1d2a-44aa-bee5-7fb53b4c7068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews.csv found!\n"
     ]
    }
   ],
   "source": [
    "ny_reviews = p.acquire_ny_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b983ddb6-110b-4a7b-8e09-e7ad2a655589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ny_reviews = ny_reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dfed25d3-b875-4b85-90da-85873092cdd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4086 entries, 155 to 59922\n",
      "Data columns (total 16 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   camis                  4086 non-null   int64  \n",
      " 1   dba                    4086 non-null   object \n",
      " 2   boro                   4086 non-null   object \n",
      " 3   phone                  4086 non-null   int64  \n",
      " 4   cuisine_description    4086 non-null   object \n",
      " 5   inspection_date        4086 non-null   object \n",
      " 6   action                 4086 non-null   object \n",
      " 7   score                  4086 non-null   int64  \n",
      " 8   grade                  4086 non-null   object \n",
      " 9   latitude               4086 non-null   float64\n",
      " 10  longitude              4086 non-null   float64\n",
      " 11  full_address           4086 non-null   object \n",
      " 12  violation_code         4086 non-null   object \n",
      " 13  violation_description  4086 non-null   object \n",
      " 14  last_inspection_date   4086 non-null   object \n",
      " 15  concatenated_reviews   4086 non-null   object \n",
      "dtypes: float64(2), int64(3), object(11)\n",
      "memory usage: 542.7+ KB\n"
     ]
    }
   ],
   "source": [
    "ny_reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dfe7abb0-c885-4634-9989-28aae4312049",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny_reviews = ny_reviews[['dba', 'concatenated_reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7c49c57f-f868-4b59-a14a-2c2c88318384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dba</th>\n",
       "      <th>concatenated_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>MEE SUM CAFE</td>\n",
       "      <td>Very authentic place. To the point that I ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>MEE SUM CAFE</td>\n",
       "      <td>Really great classic Chinese comfort food. Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>MEE SUM CAFE</td>\n",
       "      <td>Great spot cheap eats Didn’t have time to take...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>MEE SUM CAFE</td>\n",
       "      <td>Great Place for some Home Cooking Friendly a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>MEE SUM CAFE</td>\n",
       "      <td>Great dim sum cafe open early!!  Popular place...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              dba                               concatenated_reviews\n",
       "155  MEE SUM CAFE    Very authentic place. To the point that I ne...\n",
       "156  MEE SUM CAFE  Really great classic Chinese comfort food. Gre...\n",
       "157  MEE SUM CAFE  Great spot cheap eats Didn’t have time to take...\n",
       "158  MEE SUM CAFE    Great Place for some Home Cooking Friendly a...\n",
       "159  MEE SUM CAFE  Great dim sum cafe open early!!  Popular place..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ny_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fe6c06-97ce-4193-9176-da723db4e57f",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d49610-b15c-424c-909d-03479febbbd7",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00a7b6-b0db-4643-b1f7-f5310d5f7e93",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449786f6-5198-4fdc-b0d6-a82e9346a33c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077769b5-eb61-4500-bb48-140be2a89fbe",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2751d8c-f85e-4ab2-9f32-e0431238c8b6",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271d01aa-5b59-4df6-9c99-27e08998891c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d4141-60b6-4344-9e42-4c79a9014b78",
   "metadata": {},
   "source": [
    "## Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d42547-bb68-4061-ba01-526b4f2c9782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "from sklearn.metrics import classification_report as class_rep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560b564d-d88c-42c8-976d-3ac196b17328",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80adcb6-d492-46ea-80b0-7436b9914bc5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb33d5-83be-4c09-86c9-5880b741a696",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5642462-2684-4eb9-8c62-19634f12cecb",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5dc5829-6111-4769-9e3f-07b067ffc181",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62bfe33-59db-41e5-b45d-b48d3b0ca74b",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4e1bed-f843-481e-892b-fbb7a10bf967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline():\n",
    "\n",
    "    # Load and preprocess your data\n",
    "    repos_df = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    repos_df.drop(columns=(['repo', 'bigrams', 'trigrams']))\n",
    "    repos_df = repos_df.dropna()\n",
    "    \n",
    "    X = repos_df.text\n",
    "    y = repos_df.language\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    train_baseline_acc = y_train.value_counts().max() / y_train.shape[0] * 100    \n",
    "    val_baseline_acc = y_val.value_counts().max() / y_val.shape[0] * 100\n",
    "\n",
    "    print(f'\\nBaseline Accuracy')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\n\\nTrain baseline accuracy: {round(train_baseline_acc)}%\\n')\n",
    "    print(f'\\nValidation baseline accuracy: {round(val_baseline_acc)}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11525e0-a6b8-4631-a6bd-e2865f45aff7",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51873dc5-4b6f-43d0-8670-a75d3d5a66c2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42dfa3-bbe5-4167-8a6b-53b1dd20c299",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9653b80d-6b9c-44d2-85d2-9e040eaf2f44",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c741d388-6df5-4078-a603-5ebea0a843af",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2230d-4fac-486c-bfb3-4c2b9c6cd92d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e0f73-6c93-4690-bd72-69e7927f14e2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a816d2-7ceb-4dc7-94a5-f222fa6d7d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1():\n",
    "    # Load and preprocess your data\n",
    "    repos_df = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    repos_df.drop(columns=(['repo', 'bigrams', 'trigrams']))\n",
    "    repos_df = repos_df.dropna()\n",
    "\n",
    "    X = repos_df.text\n",
    "    y = repos_df.language\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create TF-IDF vectors\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    lm = LogisticRegression(\n",
    "        penalty='l2',\n",
    "        C=1.0,\n",
    "        fit_intercept=False,\n",
    "        class_weight='balanced',\n",
    "        solver='liblinear',\n",
    "        max_iter=100,\n",
    "        random_state=42\n",
    "    )\n",
    "    lm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': lm.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': lm.predict(X_val_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "\n",
    "    print(f'\\nLogisitic Regression Model (Hyperparameters Used)')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b5074f-d90c-4515-ab78-8c2447f85a36",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c937631-a452-4af7-8ffc-6e97d805fae5",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cdbdd7-f435-440d-9b38-5ff37f26312e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d0095-588b-412c-9a02-242cc4e6464c",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc2dcd-b767-4c06-ab10-1136da9878de",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940c14db-2de3-454a-b577-d0baeef07ba8",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f621517-eb32-4551-bac2-9c83a75438b2",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32f929-2856-4e8d-baf4-9c99bdb5b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2():\n",
    "    # Load and preprocess your data\n",
    "    repos_df = pd.read_csv('ny_reviews.csv', index_col=0)\n",
    "    repos_df.drop(columns=(['repo', 'bigrams', 'trigrams']))\n",
    "    repos_df = repos_df.dropna()\n",
    "\n",
    "    X = repos_df.text\n",
    "    y = repos_df.language\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create TF-IDF vectors\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    # Train KNN Model\n",
    "    knn = KNeighborsClassifier(\n",
    "    n_neighbors=2,  \n",
    "    weights='distance',  # distance\n",
    "    p=2,  # Euclidean distance\n",
    "    algorithm='auto',  # 'ball_tree', 'kd_tree', or 'brute'\n",
    "    leaf_size=30,  \n",
    "    metric='euclidean'  # You can choose other metrics or provide custom ones\n",
    "    )\n",
    "    knn.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': knn.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': knn.predict(X_val_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "\n",
    "    print(f'\\nKNearest Neighbors (Hyperparameters Used)')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fed37c-03be-4ef4-9e33-645a33400131",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368134e-2789-4cc2-ae15-4f22e966b16d",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c25bcd-ffda-49ea-906a-00d22e96098e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac656c-e4a1-4aef-9821-b5038372e349",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f491ba5-7456-43fa-9620-efb838780668",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e373719d-29d7-47d1-b41a-bb026e960e27",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4209798a-a32b-4bc8-98c9-efb88154c39e",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cff40f-fbc0-4673-b5d0-4f11ba5d5b2a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "\n",
    "def model_3():\n",
    "\n",
    "    # Load and preprocess your data\n",
    "    repos_df = pd.read_csv('processed_repos.csv', index_col=0)\n",
    "    repos_df.drop(columns=(['repo', 'bigrams', 'trigrams']))\n",
    "    repos_df = repos_df.dropna()\n",
    "    \n",
    "    # Initialize the label encoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    \n",
    "    # Encode the target labels\n",
    "    y_encoded = label_encoder.fit_transform(repos_df.language)\n",
    "    \n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(repos_df.text, y_encoded, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "    \n",
    "    # Initialize and fit the TfidfVectorizer on the training data\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    \n",
    "    # Create the XGBoost classifier instance\n",
    "    bst = XGBClassifier(n_estimators=100, max_depth=2, learning_rate=0.25, objective='multi:softprob', num_class=len(label_encoder.classes_))\n",
    "    \n",
    "    # Fit the XGBoost model on the training data\n",
    "    bst.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Predict the classes on the validation data\n",
    "    preds = bst.predict(X_val_tfidf)\n",
    "    \n",
    "    # If you want to decode the predicted labels back to their original class names:\n",
    "    preds_decoded = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': bst.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': bst.predict(X_val_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "\n",
    "    print(f'\\nXGBClassifier Model (Hyperparameters Used)')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f2918-defa-4bf5-b7ce-09434e035dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_4():\n",
    "    # Load and preprocess your data\n",
    "    repos_df = pd.read_csv('processed_repos.csv', index_col=0)\n",
    "    repos_df.drop(columns=(['repo', 'bigrams', 'trigrams']))\n",
    "    repos_df = repos_df.dropna()\n",
    "\n",
    "    X = repos_df.text\n",
    "    y = repos_df.language\n",
    "\n",
    "    # Split the data into training, validation, and test sets\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=0.7, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "    # Create TF-IDF vectors\n",
    "    tfidf = TfidfVectorizer()\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    X_val_tfidf = tfidf.transform(X_val)\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "    lm = LogisticRegression(\n",
    "    penalty='l2',  # L2 regularization (Ridge)\n",
    "    C=1.0,  # Inverse of regularization strength\n",
    "    fit_intercept=False,  # Include an intercept\n",
    "    class_weight='balanced',  # You can set class weights if needed\n",
    "    solver='liblinear',  # Choose a solver appropriate for your data\n",
    "    max_iter=100,  # You may need to increase this if the model doesn't converge\n",
    "    random_state=42  # For reproducibility\n",
    "    )\n",
    "    \n",
    "    lm.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    y_train_res = pd.DataFrame({'actual': y_train, 'preds': lm.predict(X_train_tfidf)})\n",
    "    y_val_res = pd.DataFrame({'actual': y_val, 'preds': lm.predict(X_val_tfidf)})\n",
    "    y_test_res = pd.DataFrame({'actual': y_test, 'preds': lm.predict(X_test_tfidf)})\n",
    "    train_accuracy = accuracy_score(y_train_res['actual'], y_train_res['preds'])\n",
    "    val_accuracy = accuracy_score(y_val_res['actual'], y_val_res['preds'])\n",
    "    test_accuracy = accuracy_score(y_test_res['actual'], y_test_res['preds'])\n",
    "\n",
    "    print(f'\\nFinal Model Logisitic Regression with Hyperparameter tuning')\n",
    "    print(f'==================================================')\n",
    "    print(f'\\nTrain Accuracy: {train_accuracy:.2f}\\n')\n",
    "    print(f'\\nValidation Accuracy: {val_accuracy:.2f}\\n')\n",
    "    print(f'\\nTest Accuracy: {test_accuracy:.2f}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
