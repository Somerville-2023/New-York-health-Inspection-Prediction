{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "161aa5bb-8421-43ee-8df4-3c0a2be63c29",
   "metadata": {},
   "source": [
    "# Review data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3609e61-6a6a-4123-8eef-6a5741f5006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import ds libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import acquire functions\n",
    "import nick_acquire as a\n",
    "import nick_prepare as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016606a4-b675-477b-a074-1a5a63ca0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_reviews = pd.read_csv('reviews_progress.csv')\n",
    "scrape_reviews = pd.read_csv('scraped_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab6e992-56f2-4717-bfdc-c5862c06c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_reviews.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf6b60f-d41a-4c48-aec7-2abce79d31a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded3fdd-9367-4fdf-a68c-7749fafcfc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_api_reviews(api_data):\n",
    "    df = api_data.copy()\n",
    "    cols = ['camis', 'publish_time', 'review_text', 'review_rating']\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "clean_api_reviews(api_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d70408b-448b-4969-81d7-0b3e553cf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dates(data):\n",
    "    scrape_reviews = data.copy()\n",
    "    scrape_reviews.relative_date = scrape_reviews.relative_date.apply(lambda x: x[:-4])\n",
    "    scrape_reviews.relative_date = ['1 years' if date == 'a year' else date for date in scrape_reviews.relative_date]\n",
    "    scrape_reviews.relative_date = [re.sub(r'^a', '1', date) if date[0] == 'a' else date for date in scrape_reviews.relative_date]\n",
    "    return scrape_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ffce42-e181-4b73-bad0-c35a3a2c0bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = clean_dates(scrape_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0175231-27df-4d9c-8a10-ccfb1d66f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_dates(scrape_reviews):\n",
    "    \n",
    "    dataframes = []  # Create empty list to store dataframes\n",
    "    \n",
    "    # Isolate each restaurant by id\n",
    "    for restaurant_id in scrape_reviews.id.unique():\n",
    "        # Create dataframe of ONE restaurant\n",
    "        restaurant = scrape_reviews[scrape_reviews.id == restaurant_id].copy()\n",
    "        \n",
    "        # Create df of review counts per relative_date and calculate average distribution of reviews\n",
    "        place = scrape_reviews[scrape_reviews.id == restaurant_id]\n",
    "        review_counts = pd.DataFrame(place.relative_date.value_counts())\n",
    "        review_counts['increment'] = 365/review_counts.relative_date\n",
    "        \n",
    "        # Create empty list for new dates, i variable to count increments, and previous_year to track year \n",
    "        new_dates = []\n",
    "        i = 0\n",
    "        previous_year = '1 years'\n",
    "\n",
    "        for date in restaurant.relative_date: \n",
    "            if 'years' in date:  # If date is in years, function will adjust it to estimated date\n",
    "                if date != previous_year:  # When date changes from 'x years' to 'x + 1 years' counters are reset \n",
    "                    i = 0\n",
    "                    previous_year = date\n",
    "                # Calculate adjusted date\n",
    "                adjusted_date = (365*(int(re.findall(r'\\d+', date)[0]))) + (review_counts.loc[date].increment * i)\n",
    "                i += 1\n",
    "                new_dates.append(str(round(adjusted_date)))  # Append adjsuted date\n",
    "            else:\n",
    "                new_dates.append(date)  # Append normal date if date < 1 year\n",
    "        restaurant['new_date'] = new_dates  # Replace dates with new_dates\n",
    "        dataframes.append(restaurant)  # Append dataframe to list of dataframes\n",
    "    reviews = pd.concat(dataframes)  # Join all dataframes\n",
    "    return reviews  # Return joined data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c80f60-468a-4af4-abeb-8a5b9cc7922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.read_csv('scraped_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b33bca-bfea-474c-8e1c-b175e57b0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "place = s[s.id == 41375676]\n",
    "review_counts = pd.DataFrame(place.relative_date.value_counts())\n",
    "#review_counts.rename(columns={review_counts.columns[0]:'new_name'})\n",
    "# review_counts['increment'] = 365 / review_counts.index\n",
    "review_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35303d-4c94-4436-97d6-b74610cbb940",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = adjust_dates(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd61031-2b00-4e22-873f-c4cf8ea05995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days(data):\n",
    "    reviews = data.copy()\n",
    "    new_date = []\n",
    "    for date in reviews.new_date:\n",
    "        #print(date)\n",
    "        unit = re.sub(r'[^a-z]', '', date)\n",
    "        if 'hour' in unit:\n",
    "            new_date.append('1')\n",
    "        elif 'day' in unit:\n",
    "            new_date.append(re.sub(r'[^0-9]', '', date))\n",
    "        elif 'week' in unit:\n",
    "            new_date.append(int(re.sub(r'[^0-9]', '', date))*7)\n",
    "        elif 'month' in unit:\n",
    "            new_date.append(int(re.sub(r'[^0-9]', '', date))*30)\n",
    "        else:\n",
    "            new_date.append(date)\n",
    "\n",
    "    reviews['newer_dates'] = new_date\n",
    "    reviews['final_date'] = [pd.to_datetime(retrieval_date) - timedelta(days = n) for retrieval_date,n in zip(reviews.retrieval_date, reviews.newer_dates.astype(int))]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ae918-8074-484c-ab0f-06cb1f2ae207",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = calculate_days(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d880f4-4322-4ee9-a762-0b1ccca1ae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_reviews(data):\n",
    "    final_df = data.copy()\n",
    "    cols = ['id', 'final_date', 'caption', 'rating']\n",
    "    final_df = final_df[cols]\n",
    "    final_df.rating = final_df.rating.astype(int)\n",
    "    final_df.columns = ['camis', 'publish_time', 'review_text', 'review_rating']\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afadf7-932e-4e38-ae4d-b6fe6dd34abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = clean_reviews(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a01ec89-4f4d-43a5-8b3e-246af1edafd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061455e9-a2f4-40c5-a618-8aeecba905c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_reviews = pd.read_csv('reviews_progress.csv')\n",
    "scrape_reviews = pd.read_csv('scraped_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acbd008-1fd7-43a8-8a2e-9270373a5b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep.cleanse_reviews(scrape_reviews, api_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc51ffd9-82c1-4957-b899-3537f983138b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.read_csv('reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe85bd4-7afa-45ab-bab4-46b6ee1fca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(r.publish_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3cd881-0b1e-47de-9899-a79d58ee6507",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(pd. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7ad2f-740d-44a4-a070-251651060c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
